{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLT SSD example usecase\n",
    "\n",
    "This notebook shows an example usecase of SSD object detection using Transfer Learning Toolkit.\n",
    "\n",
    "0. [Set up env variables](#head-0)\n",
    "1. [Prepare dataset and pre-trained model](#head-1) <br>\n",
    "    1.1 [Prepare tfrecords from kitti format dataset](#head-1-1) <br>\n",
    "    1.2 [Download pre-trained model](#head-1-2) <br>\n",
    "2. [Provide training specification](#head-2)\n",
    "3. [Run TLT training](#head-3)\n",
    "4. [Evaluate trained models](#head-4)\n",
    "5. [Prune trained models](#head-5)\n",
    "6. [Retrain pruned models](#head-6)\n",
    "7. [Evaluate retrained model](#head-7)\n",
    "8. [Visualize inferences](#head-8)\n",
    "9. [Deploy](#head-9)\n",
    "10. [Verify deployed model](#head-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please replace the variable with your key.\n",
      "env: KEY=ajM4bThzZnR2bDN1cTIxaWRnc2NldnFsOGw6N2YwZmJjZjQtOGNjMi00NGYyLTg3ZjMtZjQ0Mjg1M2MxZmUz\n",
      "env: USER_EXPERIMENT_DIR=/workspace/tlt-experiments/ssd\n",
      "env: DATA_DOWNLOAD_DIR=/workspace/tlt-experiments/data-sky\n",
      "env: SPECS_DIR=/workspace/tlt-experiments/ssd/specs\n"
     ]
    }
   ],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "print(\"Please replace the variable with your key.\")\n",
    "%set_env KEY=NXVoYm9hdm40NHQ3bTM1OTNiOGhmMDJkb2I6NDVjZDE2YjYtNjA1Yi00MGEzLTliMGYtZjM3MTlkNzE0NzBh\n",
    "%set_env USER_EXPERIMENT_DIR=/workspace/traffic-ai/TrafficCamNet/training\n",
    "%set_env DATA_DOWNLOAD_DIR=/workspace/traffic-ai/data\n",
    "%set_env SPECS_DIR=/workspace/tlt-experiments/ssd/specs\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will be using the KITTI detection dataset for the tutorial. To find more details please visit\n",
    " http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d. Please download the KITTI detection images (http://www.cvlibs.net/download.php?file=data_object_image_2.zip) and labels (http://www.cvlibs.net/download.php?file=data_object_label_2.zip) to $DATA_DOWNLOAD_DIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset is present\n",
    "!mkdir -p $DATA_DOWNLOAD_DIR\n",
    "!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_image_2.zip ]; then echo 'Image zip file not found, please download.'; else echo 'Found Image zip file.';fi\n",
    "!if [ ! -f $DATA_DOWNLOAD_DIR/data_object_label_2.zip ]; then echo 'Label zip file not found, please download.'; else echo 'Found Labels zip file.';fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /workspace/tlt-experiments/data-sky/data_object_image_2.zip, /workspace/tlt-experiments/data-sky/data_object_image_2.zip.zip or /workspace/tlt-experiments/data-sky/data_object_image_2.zip.ZIP.\n",
      "unzip:  cannot find or open /workspace/tlt-experiments/data-sky/data_object_label_2.zip, /workspace/tlt-experiments/data-sky/data_object_label_2.zip.zip or /workspace/tlt-experiments/data-sky/data_object_label_2.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# unpack \n",
    "!unzip -u $DATA_DOWNLOAD_DIR/data_object_image_2.zip -d $DATA_DOWNLOAD_DIR\n",
    "!unzip -u $DATA_DOWNLOAD_DIR/data_object_label_2.zip -d $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxr-xr-x 3 root root 4096 Nov 23 10:43 tfrecords\r\n",
      "drwxrwxr-x 4 1000 1000 4096 Nov 23 12:01 training\r\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "!ls -l $DATA_DOWNLOAD_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, if you have your own dataset already in a volume (or folder), you can mount the volume on `DATA_DOWNLOAD_DIR` (or create a soft link). Below shows an example:\n",
    "```bash\n",
    "# if your dataset is in /dev/sdc1\n",
    "mount /dev/sdc1 $DATA_DOWNLOAD_DIR\n",
    "\n",
    "# if your dataset is in folder /var/dataset\n",
    "ln -sf /var/dataset $DATA_DOWNLOAD_DIR\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Prepare tfrecords from kitti format dataset <a class=\"anchor\" id=\"head-1-1\"></a>\n",
    "\n",
    "* Update the tfrecords spec file to take in your kitti format dataset\n",
    "* Create the tfrecords using the tlt-dataset-convert \n",
    "* TFRecords only need to be generated once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFrecords conversion spec file for training\n",
      "kitti_config {\n",
      "  root_directory_path: \"/workspace/tlt-experiments/data-sky/training\"\n",
      "  image_dir_name: \"image_2_BDD\"\n",
      "  label_dir_name: \"label_2_BDD\"\n",
      "  image_extension: \".jpg\"\n",
      "  partition_mode: \"random\"\n",
      "  num_partitions: 2\n",
      "  val_split: 14\n",
      "  num_shards: 10\n",
      "}\n",
      "image_directory_path: \"/workspace/tlt-experiments/data-sky/training\"\n"
     ]
    }
   ],
   "source": [
    "print(\"TFrecords conversion spec file for training\")\n",
    "!cat $SPECS_DIR/ssd_tfrecords_kitti_trainval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 12:35:46.978608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "Using TensorFlow backend.\n",
      "2020-11-23 12:35:49,620 - iva.detectnet_v2.dataio.build_converter - INFO - Instantiating a kitti converter\n",
      "2020-11-23 12:35:49,855 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Num images in\n",
      "Train: 60200\tVal: 9800\n",
      "2020-11-23 12:35:49,855 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2020-11-23 12:35:49,916 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 0\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/715c8bafe7816f3bb6f309cd506049bb/execroot/ai_infra/bazel-out/k8-py3-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "2020-11-23 12:35:49,916 - tensorflow - WARNING - From /home/vpraveen/.cache/dazel/_dazel_vpraveen/715c8bafe7816f3bb6f309cd506049bb/execroot/ai_infra/bazel-out/k8-py3-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/iva/detectnet_v2/dataio/kitti_converter_lib.py:273: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "2020-11-23 12:35:51,830 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 1\n",
      "2020-11-23 12:35:53,726 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 2\n",
      "2020-11-23 12:35:55,622 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 3\n",
      "2020-11-23 12:35:57,513 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 4\n",
      "2020-11-23 12:35:59,395 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 5\n",
      "2020-11-23 12:36:01,297 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 6\n",
      "2020-11-23 12:36:03,198 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 7\n",
      "2020-11-23 12:36:05,113 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 8\n",
      "2020-11-23 12:36:06,998 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 9\n",
      "2020-11-23 12:36:08,873 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'road_sign': 60470\n",
      "b'pedestrain': 12793\n",
      "b'vehicle': 106774\n",
      "b'bicycle': 2070\n",
      "\n",
      "2020-11-23 12:36:08,873 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 0\n",
      "2020-11-23 12:36:20,610 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 1\n",
      "2020-11-23 12:36:32,218 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 2\n",
      "2020-11-23 12:36:42,442 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 3\n",
      "2020-11-23 12:36:52,659 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 4\n",
      "2020-11-23 12:37:02,982 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 5\n",
      "2020-11-23 12:37:13,267 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 6\n",
      "2020-11-23 12:37:23,539 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 7\n",
      "2020-11-23 12:37:33,783 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 8\n",
      "2020-11-23 12:37:43,990 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 9\n",
      "2020-11-23 12:37:54,262 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'road_sign': 365792\n",
      "b'vehicle': 649183\n",
      "b'bicycle': 12681\n",
      "b'pedestrain': 78642\n",
      "\n",
      "2020-11-23 12:37:54,263 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Cumulative object statistics\n",
      "2020-11-23 12:37:54,263 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'road_sign': 426262\n",
      "b'pedestrain': 91435\n",
      "b'vehicle': 755957\n",
      "b'bicycle': 14751\n",
      "\n",
      "2020-11-23 12:37:54,263 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'road_sign': b'road_sign'\n",
      "b'pedestrain': b'pedestrain'\n",
      "b'vehicle': b'vehicle'\n",
      "b'bicycle': b'bicycle'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2020-11-23 12:37:54,263 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Tfrecords generation complete.\n"
     ]
    }
   ],
   "source": [
    "# Creating a new directory for the output tfrecords dump.\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/tfrecords\n",
    "#KITTI trainval\n",
    "!tlt-dataset-convert -d $SPECS_DIR/ssd_tfrecords_kitti_trainval.txt \\\n",
    "                     -o $DATA_DOWNLOAD_DIR/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 117896\r\n",
      "-rw-r--r-- 1 root root  1703208 Nov 23 12:35 kitti_trainval-fold-000-of-002-shard-00000-of-00010\r\n",
      "-rw-r--r-- 1 root root  1709946 Nov 23 12:35 kitti_trainval-fold-000-of-002-shard-00001-of-00010\r\n",
      "-rw-r--r-- 1 root root  1708383 Nov 23 12:35 kitti_trainval-fold-000-of-002-shard-00002-of-00010\r\n",
      "-rw-r--r-- 1 root root  1695353 Nov 23 12:35 kitti_trainval-fold-000-of-002-shard-00003-of-00010\r\n",
      "-rw-r--r-- 1 root root  1682108 Nov 23 12:35 kitti_trainval-fold-000-of-002-shard-00004-of-00010\r\n",
      "-rw-r--r-- 1 root root  1702313 Nov 23 12:36 kitti_trainval-fold-000-of-002-shard-00005-of-00010\r\n",
      "-rw-r--r-- 1 root root  1716410 Nov 23 12:36 kitti_trainval-fold-000-of-002-shard-00006-of-00010\r\n",
      "-rw-r--r-- 1 root root  1736492 Nov 23 12:36 kitti_trainval-fold-000-of-002-shard-00007-of-00010\r\n",
      "-rw-r--r-- 1 root root  1676991 Nov 23 12:36 kitti_trainval-fold-000-of-002-shard-00008-of-00010\r\n",
      "-rw-r--r-- 1 root root  1674860 Nov 23 12:36 kitti_trainval-fold-000-of-002-shard-00009-of-00010\r\n",
      "-rw-r--r-- 1 root root 10365930 Nov 23 12:36 kitti_trainval-fold-001-of-002-shard-00000-of-00010\r\n",
      "-rw-r--r-- 1 root root 10333705 Nov 23 12:36 kitti_trainval-fold-001-of-002-shard-00001-of-00010\r\n",
      "-rw-r--r-- 1 root root 10356869 Nov 23 12:36 kitti_trainval-fold-001-of-002-shard-00002-of-00010\r\n",
      "-rw-r--r-- 1 root root 10332965 Nov 23 12:36 kitti_trainval-fold-001-of-002-shard-00003-of-00010\r\n",
      "-rw-r--r-- 1 root root 10462945 Nov 23 12:37 kitti_trainval-fold-001-of-002-shard-00004-of-00010\r\n",
      "-rw-r--r-- 1 root root 10408180 Nov 23 12:37 kitti_trainval-fold-001-of-002-shard-00005-of-00010\r\n",
      "-rw-r--r-- 1 root root 10373648 Nov 23 12:37 kitti_trainval-fold-001-of-002-shard-00006-of-00010\r\n",
      "-rw-r--r-- 1 root root 10327659 Nov 23 12:37 kitti_trainval-fold-001-of-002-shard-00007-of-00010\r\n",
      "-rw-r--r-- 1 root root 10310837 Nov 23 12:37 kitti_trainval-fold-001-of-002-shard-00008-of-00010\r\n",
      "-rw-r--r-- 1 root root 10409314 Nov 23 12:37 kitti_trainval-fold-001-of-002-shard-00009-of-00010\r\n"
     ]
    }
   ],
   "source": [
    "!ls -rlt $DATA_DOWNLOAD_DIR/tfrecords/kitti_trainval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download pre-trained model <a class=\"anchor\" id=\"head-1-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use NGC CLI to get the pre-trained models. For more details, go to [ngc.nvidia.com](ngc.nvidia.com) and click the SETUP on the navigation bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/tlt_pretrained_object_detection:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/pretrained_resnet18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tlt_pretrained_object_detection:resnet18 --dest $USER_EXPERIMENT_DIR/pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that model is downloaded into dir.\n",
      "total 91096\n",
      "-rwxrwxrwx 1 root root 93278448 Nov 23 07:48 resnet_18.hdf5\n"
     ]
    }
   ],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $USER_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_object_detection_vresnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Provide training specification <a class=\"anchor\" id=\"head-2\"></a>\n",
    "* Tfrecords for the train datasets\n",
    "    * In order to use the newly generated tfrecords, update the dataset_config parameter in the spec file at `$SPECS_DIR/ssd_train_resnet18_kitti.txt` \n",
    "    * Update the fold number to use for evaluation. In case of random data split, please use fold 0 only\n",
    "    * For sequence wise you may use any fold generated from the dataset convert tool\n",
    "* Augmentation parameters for on the fly data augmentation\n",
    "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n",
    "* Whether to use quantization aware training (QAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enable QAT training on sample spec file, uncomment following lines\n",
    "# !sed -i \"s/enable_qat: false/enable_qat: true/g\" $SPECS_DIR/ssd_train_resnet18_kitti.txt\n",
    "# !sed -i \"s/enable_qat: false/enable_qat: true/g\" $SPECS_DIR/ssd_retrain_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, the sample spec file disables QAT training. You can force non-QAT training by running lines below\n",
    "# !sed -i \"s/enable_qat: true/enable_qat: false/g\" $SPECS_DIR/ssd_train_resnet18_kitti.txt\n",
    "# !sed -i \"s/enable_qat: true/enable_qat: false/g\" $SPECS_DIR/ssd_retrain_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_seed: 42\r\n",
      "ssd_config {\r\n",
      "  aspect_ratios_global: \"[1.0, 2.0, 0.5, 3.0, 1.0/3.0]\"\r\n",
      "  scales: \"[0.05, 0.1, 0.25, 0.4, 0.55, 0.7, 0.85]\"\r\n",
      "  two_boxes_for_ar1: true\r\n",
      "  clip_boxes: false\r\n",
      "  loss_loc_weight: 0.8\r\n",
      "  focal_loss_alpha: 0.25\r\n",
      "  focal_loss_gamma: 2.0\r\n",
      "  variances: \"[0.1, 0.1, 0.2, 0.2]\"\r\n",
      "  arch: \"resnet\"\r\n",
      "  nlayers: 18\r\n",
      "  freeze_bn: false\r\n",
      "  freeze_blocks: 0\r\n",
      "}\r\n",
      "training_config {\r\n",
      "  batch_size_per_gpu: 16\r\n",
      "  num_epochs: 80\r\n",
      "  enable_qat: false\r\n",
      "  learning_rate {\r\n",
      "  soft_start_annealing_schedule {\r\n",
      "    min_learning_rate: 5e-5\r\n",
      "    max_learning_rate: 2e-2\r\n",
      "    soft_start: 0.15\r\n",
      "    annealing: 0.8\r\n",
      "    }\r\n",
      "  }\r\n",
      "  regularizer {\r\n",
      "    type: L1\r\n",
      "    weight: 3e-5\r\n",
      "  }\r\n",
      "}\r\n",
      "eval_config {\r\n",
      "  validation_period_during_training: 10\r\n",
      "  average_precision_mode: SAMPLE\r\n",
      "  batch_size: 16\r\n",
      "  matching_iou_threshold: 0.5\r\n",
      "}\r\n",
      "nms_config {\r\n",
      "  confidence_threshold: 0.01\r\n",
      "  clustering_iou_threshold: 0.6\r\n",
      "  top_k: 200\r\n",
      "}\r\n",
      "augmentation_config {\r\n",
      "  preprocessing {\r\n",
      "    output_image_width: 1248\r\n",
      "    output_image_height: 384\r\n",
      "    output_image_channel: 3\r\n",
      "    crop_right: 1248\r\n",
      "    crop_bottom: 384\r\n",
      "    min_bbox_width: 1.0\r\n",
      "    min_bbox_height: 1.0\r\n",
      "  }\r\n",
      "  spatial_augmentation {\r\n",
      "    hflip_probability: 0.5\r\n",
      "    vflip_probability: 0.0\r\n",
      "    zoom_min: 0.7\r\n",
      "    zoom_max: 1.8\r\n",
      "    translate_max_x: 8.0\r\n",
      "    translate_max_y: 8.0\r\n",
      "  }\r\n",
      "  color_augmentation {\r\n",
      "    hue_rotation_max: 25.0\r\n",
      "    saturation_shift_max: 0.20000000298\r\n",
      "    contrast_scale_max: 0.10000000149\r\n",
      "    contrast_center: 0.5\r\n",
      "  }\r\n",
      "}\r\n",
      "dataset_config {\r\n",
      "  data_sources: {\r\n",
      "    tfrecords_path: \"/workspace/tlt-experiments/data-sky/tfrecords/kitti_trainval/kitti_trainval*\"\r\n",
      "    image_directory_path: \"/workspace/tlt-experiments/data-sky/training\"\r\n",
      "  }\r\n",
      "  image_extension: \"jpg\"\r\n",
      " \r\n",
      "   target_class_mapping {\r\n",
      "      key: \"road_sign\"\r\n",
      "      value: \"road_sign\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "      key: \"pedestrian\"\r\n",
      "      value: \"pedestrian\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "      key: \"vehicle\"\r\n",
      "      value: \"vehicle\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "      key: \"bicycle\"\r\n",
      "      value: \"bicycle\"\r\n",
      "  }\r\n",
      "\r\n",
      "\r\n",
      "validation_fold: 0\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat $SPECS_DIR/ssd_train_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run TLT training <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* Provide the sample spec file and the output directory location for models\n",
    "* WARNING: training will take several hours or one day to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_unpruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run with multigpu, please change --gpus based on the number of available GPUs in your machine.\n",
      "Using TensorFlow backend.\n",
      "2020-11-23 12:31:20.089955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-11-23 12:31:22.950161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-11-23 12:31:22.963141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:22.964052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-23 12:31:22.964084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-11-23 12:31:22.965418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-11-23 12:31:22.966406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-11-23 12:31:22.966720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-11-23 12:31:22.968197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-11-23 12:31:22.969312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-11-23 12:31:22.972373: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-11-23 12:31:22.972569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:22.973274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:22.974124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-11-23 12:31:22.974170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-11-23 12:31:23.360031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-23 12:31:23.360082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-11-23 12:31:23.360104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-11-23 12:31:23.360530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:23.361098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:23.361638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:23.362152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10731 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0, compute capability: 5.2)\n",
      "2020-11-23 12:31:23,363 [INFO] /usr/local/lib/python3.6/dist-packages/iva/ssd/utils/spec_loader.pyc: Merging specification from /workspace/tlt-experiments/ssd/specs/ssd_train_resnet18_kitti.txt\n",
      "2020-11-23 12:31:23,369 [INFO] iva.ssd.scripts.train: Loading pretrained weights. This may take a while...\n",
      "2020-11-23 12:31:29,445 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2020-11-23 12:31:29,445 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2020-11-23 12:31:29,445 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2020-11-23 12:31:29,445 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 4, io threads: 8, compute threads: 4, buffered batches: 4\n",
      "2020-11-23 12:31:29,446 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 60200, number of sources: 1, batch size per gpu: 16, steps: 3763\n",
      "2020-11-23 12:31:29,575 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2020-11-23 12:31:29.612340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:29.612875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-11-23 12:31:29.612910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-11-23 12:31:29.612967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-11-23 12:31:29.613015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-11-23 12:31:29.613046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-11-23 12:31:29.613086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-11-23 12:31:29.613117: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-11-23 12:31:29.613148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-11-23 12:31:29.613225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:29.613743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-23 12:31:29.614221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-11-23 12:31:29,871 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2020-11-23 12:31:29,879 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2020-11-23 12:31:29,879 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2020-11-23 12:32:44,293 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2020-11-23 12:32:44,293 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2020-11-23 12:32:44,293 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2020-11-23 12:32:44,294 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 4, io threads: 8, compute threads: 4, buffered batches: 4\n",
      "2020-11-23 12:32:44,294 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 9800, number of sources: 1, batch size per gpu: 16, steps: 613\n",
      "2020-11-23 12:32:44,329 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 12:32:44,612 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2020-11-23 12:32:44,618 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2020-11-23 12:32:44,618 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (16, 3, 384, 1248)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (16, 64, 192, 624)   9408        Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (16, 64, 192, 624)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (16, 64, 192, 624)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (16, 64, 96, 312)    36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (16, 64, 96, 312)    256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (16, 64, 96, 312)    0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (16, 64, 96, 312)    36864       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (16, 64, 96, 312)    4096        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (16, 64, 96, 312)    256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (16, 64, 96, 312)    256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (16, 64, 96, 312)    0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (16, 64, 96, 312)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (16, 64, 96, 312)    36864       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (16, 64, 96, 312)    256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (16, 64, 96, 312)    0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (16, 64, 96, 312)    36864       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_shortcut (Conv2D) (16, 64, 96, 312)    4096        block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (16, 64, 96, 312)    256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_shortcut (BatchNorm (16, 64, 96, 312)    256         block_1b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (16, 64, 96, 312)    0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (16, 64, 96, 312)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (16, 128, 48, 156)   73728       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (16, 128, 48, 156)   512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (16, 128, 48, 156)   0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (16, 128, 48, 156)   147456      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (16, 128, 48, 156)   8192        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (16, 128, 48, 156)   512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (16, 128, 48, 156)   512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (16, 128, 48, 156)   0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (16, 128, 48, 156)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (16, 128, 48, 156)   147456      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (16, 128, 48, 156)   512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (16, 128, 48, 156)   0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (16, 128, 48, 156)   147456      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_shortcut (Conv2D) (16, 128, 48, 156)   16384       block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (16, 128, 48, 156)   512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_shortcut (BatchNorm (16, 128, 48, 156)   512         block_2b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (16, 128, 48, 156)   0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (16, 128, 48, 156)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (16, 256, 24, 78)    294912      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (16, 256, 24, 78)    1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (16, 256, 24, 78)    0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (16, 256, 24, 78)    589824      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (16, 256, 24, 78)    32768       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (16, 256, 24, 78)    1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (16, 256, 24, 78)    1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (16, 256, 24, 78)    0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (16, 256, 24, 78)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (16, 256, 24, 78)    589824      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (16, 256, 24, 78)    1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (16, 256, 24, 78)    0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (16, 256, 24, 78)    589824      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_shortcut (Conv2D) (16, 256, 24, 78)    65536       block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (16, 256, 24, 78)    1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_shortcut (BatchNorm (16, 256, 24, 78)    1024        block_3b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (16, 256, 24, 78)    0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (16, 256, 24, 78)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (16, 512, 24, 78)    1179648     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (16, 512, 24, 78)    2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (16, 512, 24, 78)    0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (16, 512, 24, 78)    2359296     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (16, 512, 24, 78)    131072      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (16, 512, 24, 78)    2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (16, 512, 24, 78)    2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (16, 512, 24, 78)    0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (16, 512, 24, 78)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (16, 512, 24, 78)    2359296     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (16, 512, 24, 78)    2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (16, 512, 24, 78)    0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (16, 512, 24, 78)    2359296     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_shortcut (Conv2D) (16, 512, 24, 78)    262144      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (16, 512, 24, 78)    2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_shortcut (BatchNorm (16, 512, 24, 78)    2048        block_4b_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (16, 512, 24, 78)    0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4b_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (16, 512, 24, 78)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_0_conv_0 (Conv (16, 256, 24, 78)    131328      block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_0_relu_0 (ReLU (16, 256, 24, 78)    0           ssd_expand_block_0_conv_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_0_conv_1 (Conv (16, 256, 24, 78)    589824      ssd_expand_block_0_relu_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_0_bn_1 (BatchN (16, 256, 24, 78)    1024        ssd_expand_block_0_conv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_0_relu_1 (ReLU (16, 256, 24, 78)    0           ssd_expand_block_0_bn_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_1_conv_0 (Conv (16, 128, 24, 78)    32896       ssd_expand_block_0_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_1_relu_0 (ReLU (16, 128, 24, 78)    0           ssd_expand_block_1_conv_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_1_conv_1 (Conv (16, 256, 12, 39)    294912      ssd_expand_block_1_relu_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_1_bn_1 (BatchN (16, 256, 12, 39)    1024        ssd_expand_block_1_conv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_1_relu_1 (ReLU (16, 256, 12, 39)    0           ssd_expand_block_1_bn_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_2_conv_0 (Conv (16, 64, 12, 39)     16448       ssd_expand_block_1_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_2_relu_0 (ReLU (16, 64, 12, 39)     0           ssd_expand_block_2_conv_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_2_conv_1 (Conv (16, 128, 6, 20)     73728       ssd_expand_block_2_relu_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_2_bn_1 (BatchN (16, 128, 6, 20)     512         ssd_expand_block_2_conv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_2_relu_1 (ReLU (16, 128, 6, 20)     0           ssd_expand_block_2_bn_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_3_conv_0 (Conv (16, 64, 6, 20)      8256        ssd_expand_block_2_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_3_relu_0 (ReLU (16, 64, 6, 20)      0           ssd_expand_block_3_conv_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_3_conv_1 (Conv (16, 128, 3, 10)     73728       ssd_expand_block_3_relu_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_3_bn_1 (BatchN (16, 128, 3, 10)     512         ssd_expand_block_3_conv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_3_relu_1 (ReLU (16, 128, 3, 10)     0           ssd_expand_block_3_bn_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_4_conv_0 (Conv (16, 64, 3, 10)      8256        ssd_expand_block_3_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_4_relu_0 (ReLU (16, 64, 3, 10)      0           ssd_expand_block_4_conv_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_4_conv_1 (Conv (16, 128, 2, 5)      73728       ssd_expand_block_4_relu_0[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_4_bn_1 (BatchN (16, 128, 2, 5)      512         ssd_expand_block_4_conv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_expand_block_4_relu_1 (ReLU (16, 128, 2, 5)      0           ssd_expand_block_4_bn_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "ssd_conf_0 (Conv2D)             (16, 24, 48, 156)    27672       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ssd_conf_1 (Conv2D)             (16, 24, 24, 78)     55320       ssd_expand_block_0_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_conf_2 (Conv2D)             (16, 24, 12, 39)     55320       ssd_expand_block_1_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_conf_3 (Conv2D)             (16, 24, 6, 20)      27672       ssd_expand_block_2_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_conf_4 (Conv2D)             (16, 24, 3, 10)      27672       ssd_expand_block_3_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_conf_5 (Conv2D)             (16, 24, 2, 5)       27672       ssd_expand_block_4_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (16, 48, 156, 24)    0           ssd_conf_0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (16, 24, 78, 24)     0           ssd_conf_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (16, 12, 39, 24)     0           ssd_conf_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (16, 6, 20, 24)      0           ssd_conf_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (16, 3, 10, 24)      0           ssd_conf_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (16, 2, 5, 24)       0           ssd_conf_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "ssd_loc_0 (Conv2D)              (16, 24, 48, 156)    27672       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ssd_loc_1 (Conv2D)              (16, 24, 24, 78)     55320       ssd_expand_block_0_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_loc_2 (Conv2D)              (16, 24, 12, 39)     55320       ssd_expand_block_1_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_loc_3 (Conv2D)              (16, 24, 6, 20)      27672       ssd_expand_block_2_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_loc_4 (Conv2D)              (16, 24, 3, 10)      27672       ssd_expand_block_3_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_loc_5 (Conv2D)              (16, 24, 2, 5)       27672       ssd_expand_block_4_relu_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conf_reshape_0 (Reshape)        (16, 44928, 1, 4)    0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conf_reshape_1 (Reshape)        (16, 11232, 1, 4)    0           permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conf_reshape_2 (Reshape)        (16, 2808, 1, 4)     0           permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conf_reshape_3 (Reshape)        (16, 720, 1, 4)      0           permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conf_reshape_4 (Reshape)        (16, 180, 1, 4)      0           permute_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conf_reshape_5 (Reshape)        (16, 60, 1, 4)       0           permute_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (16, 48, 156, 24)    0           ssd_loc_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_8 (Permute)             (16, 24, 78, 24)     0           ssd_loc_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_9 (Permute)             (16, 12, 39, 24)     0           ssd_loc_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_10 (Permute)            (16, 6, 20, 24)      0           ssd_loc_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_11 (Permute)            (16, 3, 10, 24)      0           ssd_loc_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_12 (Permute)            (16, 2, 5, 24)       0           ssd_loc_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_anchor_0 (AnchorBoxes)      (16, 7488, 6, 8)     0           ssd_loc_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_anchor_1 (AnchorBoxes)      (16, 1872, 6, 8)     0           ssd_loc_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_anchor_2 (AnchorBoxes)      (16, 468, 6, 8)      0           ssd_loc_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_anchor_3 (AnchorBoxes)      (16, 120, 6, 8)      0           ssd_loc_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_anchor_4 (AnchorBoxes)      (16, 30, 6, 8)       0           ssd_loc_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ssd_anchor_5 (AnchorBoxes)      (16, 10, 6, 8)       0           ssd_loc_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf (Concatenate)         (16, 59928, 1, 4)    0           conf_reshape_0[0][0]             \n",
      "                                                                 conf_reshape_1[0][0]             \n",
      "                                                                 conf_reshape_2[0][0]             \n",
      "                                                                 conf_reshape_3[0][0]             \n",
      "                                                                 conf_reshape_4[0][0]             \n",
      "                                                                 conf_reshape_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loc_reshape_0 (Reshape)         (16, 44928, 1, 4)    0           permute_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loc_reshape_1 (Reshape)         (16, 11232, 1, 4)    0           permute_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loc_reshape_2 (Reshape)         (16, 2808, 1, 4)     0           permute_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loc_reshape_3 (Reshape)         (16, 720, 1, 4)      0           permute_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_reshape_4 (Reshape)         (16, 180, 1, 4)      0           permute_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "loc_reshape_5 (Reshape)         (16, 60, 1, 4)       0           permute_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "anchor_reshape_0 (Reshape)      (16, 44928, 1, 8)    0           ssd_anchor_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "anchor_reshape_1 (Reshape)      (16, 11232, 1, 8)    0           ssd_anchor_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "anchor_reshape_2 (Reshape)      (16, 2808, 1, 8)     0           ssd_anchor_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "anchor_reshape_3 (Reshape)      (16, 720, 1, 8)      0           ssd_anchor_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "anchor_reshape_4 (Reshape)      (16, 180, 1, 8)      0           ssd_anchor_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "anchor_reshape_5 (Reshape)      (16, 60, 1, 8)       0           ssd_anchor_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mbox_conf_sigmoid (Activation)  (16, 59928, 1, 4)    0           mbox_conf[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mbox_loc (Concatenate)          (16, 59928, 1, 4)    0           loc_reshape_0[0][0]              \n",
      "                                                                 loc_reshape_1[0][0]              \n",
      "                                                                 loc_reshape_2[0][0]              \n",
      "                                                                 loc_reshape_3[0][0]              \n",
      "                                                                 loc_reshape_4[0][0]              \n",
      "                                                                 loc_reshape_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mbox_priorbox (Concatenate)     (16, 59928, 1, 8)    0           anchor_reshape_0[0][0]           \n",
      "                                                                 anchor_reshape_1[0][0]           \n",
      "                                                                 anchor_reshape_2[0][0]           \n",
      "                                                                 anchor_reshape_3[0][0]           \n",
      "                                                                 anchor_reshape_4[0][0]           \n",
      "                                                                 anchor_reshape_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (16, 59928, 1, 16)   0           mbox_conf_sigmoid[0][0]          \n",
      "                                                                 mbox_loc[0][0]                   \n",
      "                                                                 mbox_priorbox[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "ssd_predictions (Reshape)       (16, 59928, 16)      0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 13,291,808\n",
      "Trainable params: 13,268,960\n",
      "Non-trainable params: 22,848\n",
      "__________________________________________________________________________________________________\n",
      "2020-11-23 12:32:50,262 [INFO] iva.ssd.scripts.train: Number of images in the training dataset:\t 60200\n",
      "2020-11-23 12:32:50,262 [INFO] iva.ssd.scripts.train: Number of images in the validation dataset:\t  9800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2020-11-23 12:33:01.956781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "/usr/local/bin/tlt-train: line 32:  1172 Illegal instruction     (core dumped) tlt-train-g1 ${PYTHON_ARGS[*]}\n"
     ]
    }
   ],
   "source": [
    "!export TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "print(\"To run with multigpu, please change --gpus based on the number of available GPUs in your machine.\")\n",
    "!tlt-train ssd -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n",
    "               -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "               -k $KEY \\\n",
    "               -m $USER_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_object_detection_vresnet18/resnet_18.hdf5 \\\n",
    "               --gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To resume from checkpoint, please uncomment and run this instead. Change last two arguments accordingly.\")\n",
    "# !tlt-train ssd -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n",
    "#                -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "#                -k $KEY \\\n",
    "#                -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_001.tlt \\\n",
    "#                --gpus 1 \\\n",
    "#                --initial_epoch 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model for each epoch:')\n",
    "print('---------------------')\n",
    "!ls -ltrh $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n",
    "!cat $USER_EXPERIMENT_DIR/experiment_dir_unpruned/ssd_training_log_resnet18.csv\n",
    "%set_env EPOCH=080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate trained models <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt-evaluate ssd -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n",
    "                  -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                  -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prune trained models <a class=\"anchor\" id=\"head-5\"></a>\n",
    "* Specify pre-trained model\n",
    "* Equalization criterion (`Only for resnets as they have element wise operations or MobileNets.`)\n",
    "* Threshold for pruning.\n",
    "* A key to save and load the model\n",
    "* Output directory to store the model\n",
    "\n",
    "Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold value depends on the dataset and the model. `0.5` in the block below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tlt-prune -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/experiment_dir_pruned/ssd_resnet18_pruned.tlt \\\n",
    "           -eq intersection \\\n",
    "           -pth 0.1 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_pruned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain pruned models <a class=\"anchor\" id=\"head-6\"></a>\n",
    "* Model needs to be re-trained to bring back accuracy after pruning\n",
    "* Specify re-training specification\n",
    "* WARNING: training will take several hours or one day to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the retrain spec file. \n",
    "# Here we have updated the spec file to include the newly pruned model as a pretrained weights.\n",
    "!cat $SPECS_DIR/ssd_retrain_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining using the pruned model as pretrained weights \n",
    "!tlt-train ssd --gpus 1 \\\n",
    "               -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "               -r $USER_EXPERIMENT_DIR/experiment_dir_retrain \\\n",
    "               -m $USER_EXPERIMENT_DIR/experiment_dir_pruned/ssd_resnet18_pruned.tlt \\\n",
    "               -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing the newly retrained model.\n",
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n",
    "!cat $USER_EXPERIMENT_DIR/experiment_dir_retrain/ssd_training_log_resnet18.csv\n",
    "%set_env EPOCH=080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate retrained model <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-evaluate ssd -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "                  -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                  -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize inferences <a class=\"anchor\" id=\"head-8\"></a>\n",
    "In this section, we run the tlt-infer tool to generate inferences on the trained models and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy some test images\n",
    "!mkdir -p /workspace/examples/ssd/test_samples\n",
    "!cp $DATA_DOWNLOAD_DIR/testing/image_2/00000* /workspace/examples/ssd/test_samples/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running inference for detection on n images\n",
    "!tlt-infer ssd -i /workspace/examples/ssd/test_samples \\\n",
    "               -o $USER_EXPERIMENT_DIR/ssd_infer_images \\\n",
    "               -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "               -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "               -l $USER_EXPERIMENT_DIR/ssd_infer_labels \\\n",
    "               -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tlt-infer` tool produces two outputs. \n",
    "1. Overlain images in `$USER_EXPERIMENT_DIR/ssd_infer_images`\n",
    "2. Frame by frame bbox labels in kitti format located in `$USER_EXPERIMENT_DIR/ssd_infer_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import ceil\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
    "    output_path = os.path.join(os.environ['USER_EXPERIMENT_DIR'], image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx // num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sample images.\n",
    "OUTPUT_PATH = 'ssd_infer_images' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 9 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deploy! <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you trained a non-QAT model, you may export in FP32, FP16 or INT8 mode using the code block below. For INT8, you need to provide calibration image directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tlt-export will fail if .etlt already exists. So we clear the export folder before tlt-export\n",
    "!rm -rf $USER_EXPERIMENT_DIR/export\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/export\n",
    "# Export in FP32 mode. Change --data_type to fp16 for FP16 mode\n",
    "!tlt-export ssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n",
    "                -k $KEY \\\n",
    "                -o $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt \\\n",
    "                -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "                --batch_size 16 \\\n",
    "                --data_type fp32\n",
    "\n",
    "# Uncomment to export in INT8 mode (generate calibration cache file).\n",
    "# !tlt-export ssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt  \\\n",
    "#                 -o $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt \\\n",
    "#                 -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "#                 -k $KEY \\\n",
    "#                 --cal_image_dir  $USER_EXPERIMENT_DIR/data/testing/image_2 \\\n",
    "#                 --data_type int8 \\\n",
    "#                 --batch_size 16 \\\n",
    "#                 --batches 10 \\\n",
    "#                 --cal_cache_file $USER_EXPERIMENT_DIR/export/cal.bin  \\\n",
    "#                 --cal_data_file $USER_EXPERIMENT_DIR/export/cal.tensorfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Note:` In this example, for ease of execution we restrict the number of calibrating batches to 10. TLT recommends the use of at least 10% of the training dataset for int8 calibration.\n",
    "\n",
    "If you train a QAT model, you may only export in INT8 mode using following code block. This generates an etlt file and the corresponding calibration cache. You can throw away the calibration cache and just use the etlt file in tlt-converter or DeepStream for FP32 or FP16 mode. But please note this gives sub-optimal results. If you want to deploy in FP32 or FP16, you should disable QAT in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to export QAT model in INT8 mode (generate calibration cache file).\n",
    "# !rm -rf $USER_EXPERIMENT_DIR/export\n",
    "# !mkdir -p $USER_EXPERIMENT_DIR/export\n",
    "# !tlt-export ssd -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt  \\\n",
    "#                 -o $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt \\\n",
    "#                 -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "#                 -k $KEY \\\n",
    "#                 --data_type int8 \\\n",
    "#                 --cal_cache_file $USER_EXPERIMENT_DIR/export/cal.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify engine generation using the `tlt-converter` utility included with the docker.\n",
    "\n",
    "The `tlt-converter` produces optimized tensorrt engines for the platform that it resides on. Therefore, to get maximum performance, please instantiate this docker and execute the `tlt-converter` command, with the exported `.etlt` file and calibration cache (for int8 mode) on your target device. The converter utility included in this docker only works for x86 devices, with discrete NVIDIA GPU's. \n",
    "\n",
    "For the jetson devices, please download the converter for jetson from the dev zone link [here](https://developer.nvidia.com/tlt-converter). \n",
    "\n",
    "If you choose to integrate your model into deepstream directly, you may do so by simply copying the exported `.etlt` file along with the calibration cache to the target device and updating the spec file that configures the `gst-nvinfer` element to point to this newly exported model. Usually this file is called `config_infer_primary.txt` for detection models and `config_infer_secondary_*.txt` for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorRT engine (FP32)\n",
    "!tlt-converter -k $KEY \\\n",
    "               -d 3,384,1248 \\\n",
    "               -o NMS \\\n",
    "               -e $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "               -m 16 \\\n",
    "               -t fp32 \\\n",
    "               -i nchw \\\n",
    "               $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt\n",
    "\n",
    "# Convert to TensorRT engine (FP16)\n",
    "# !tlt-converter -k $KEY \\\n",
    "#                -d 3,384,1248 \\\n",
    "#                -o NMS \\\n",
    "#                -e $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "#                -m 16 \\\n",
    "#                -t fp16 \\\n",
    "#                -i nchw \\\n",
    "#                $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt\n",
    "\n",
    "# Convert to TensorRT engine (INT8).\n",
    "# !tlt-converter -k $KEY  \\\n",
    "#                -d 3,384,1248 \\\n",
    "#                -o NMS \\\n",
    "#                -c $USER_EXPERIMENT_DIR/export/cal.bin \\\n",
    "#                -e $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "#                -b 8 \\\n",
    "#                -m 16 \\\n",
    "#                -t int8 \\\n",
    "#                -i nchw \\\n",
    "#                $USER_EXPERIMENT_DIR/export/ssd_resnet18_epoch_$EPOCH.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported engine:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/export/trt.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verify the deployed model <a class=\"anchor\" id=\"head-10\"></a>\n",
    "Verify the converted engine by visualizing TensorRT inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer using TensorRT engine\n",
    "\n",
    "# The engine batch size once created, cannot be alterred. So if you wish to run with a different batch-size,\n",
    "# please re-run tlt-convert.\n",
    "\n",
    "!tlt-infer ssd -m $USER_EXPERIMENT_DIR/export/trt.engine \\\n",
    "               -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n",
    "               -i /workspace/examples/ssd/test_samples \\\n",
    "               -o $USER_EXPERIMENT_DIR/ssd_infer_images \\\n",
    "               -t 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sample images.\n",
    "OUTPUT_PATH = 'ssd_infer_images' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 3 # number of columns in the visualizer grid.\n",
    "IMAGES = 9 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
